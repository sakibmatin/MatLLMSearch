# MatLLMSearch Models Configuration
# Supports local models via vLLM, OpenAI GPT, and DeepSeek models

# Local models via vLLM
meta-llama/Meta-Llama-3.1-70B-Instruct:
  provider: local
  model: meta-llama/Meta-Llama-3.1-70B-Instruct
  credentials: null
  use_vllm: true
  vllm_kwargs:
    tensor_parallel_size: 4
    gpu_memory_utilization: 0.9
    max_model_len: 8192
    max_num_seqs: 8
    dtype: "bfloat16"
    enforce_eager: true
  __call_args:
    temperature: 1.0
    max_tokens: 8000

# OpenAI Models (requires API key)
openai/gpt-4o:
  provider: openai
  model: gpt-4o
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

openai/gpt-4o-mini:
  provider: openai
  model: gpt-4o-mini
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

openai/gpt-5-mini:
  provider: openai
  model: gpt-5-mini
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

openai/gpt-5:
  provider: openai
  model: gpt-5
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

openai/gpt-5-chat:
  provider: openai
  model: gpt-5-chat-latest
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

openai/gpt-3.5-turbo:
  provider: openai
  model: gpt-3.5-turbo
  credentials: openai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000


# Additional popular models for materials science
mistral/mistral-large-2407:
  provider: local
  model: mistralai/Mistral-Large-Instruct-2407
  credentials: null
  __call_args:
    temperature: 1.0
    max_new_tokens: 8000

anthropic/claude-3-5-sonnet-20241022:
  provider: anthropic
  model: claude-3-5-sonnet-20241022
  credentials: anthropic_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

# Claude Sonnet 4.5
anthropic/claude-sonnet-4-5:
  provider: anthropic
  model: claude-sonnet-4-5
  credentials: anthropic_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

# DeepSeek Reasoner
deepseek/deepseek-reasoner:
  provider: deepseek
  model: deepseek-reasoner
  credentials: deepseek_creds
  __call_args:
    temperature: 1.0
    max_tokens: 16000

deepseek/deepseek-chat:
  provider: deepseek
  model: deepseek-chat
  credentials: deepseek_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000

# Grok-4
xai/grok-4:
  provider: xai
  model: grok-4
  credentials: xai_creds
  __call_args:
    temperature: 1.0
    max_tokens: 8000
